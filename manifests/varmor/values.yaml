# Default values for varmor.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

forceNamespace:
  enabled: false
  namespace: varmor

nameOverride: ""
fullnameOverride: ""

metrics:
  enabled: false
  serviceMonitorEnabled: false
#  syncMetricsSecond: 10

restartExistWorkloads:
  enabled: true

bpfExclusiveMode:
  enabled: false

appArmorLsmEnforcer:
  enabled: true

bpfLsmEnforcer:
  enabled: false

unloadAllAaProfiles:
  enabled: false

removeAllSeccompProfiles:
  enabled: false

# [Experimental feature]
behaviorModeling:
  enabled: false

image:
  registry: ""
  namespace: varmor
  username: ""
  password: ""

imagePullSecrets:
- name: varmor-image-pull-secret

manager:
  name: manager

  replicaCount: 3

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 10001
    runAsGroup: 10001

  image:
    name: varmor
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
      - MKNOD
      - NET_RAW

  args: []

  behaviorModeling:
    args:
    - --enableBehaviorModeling
    # The volume saves the ArmorProfileModel objects in the manager pod
    volumeMounts:
    - mountPath: /var/log/varmor/apmdata
      name: data-volume
    volumes:
    - emptyDir:
        sizeLimit: 500Mi
      name: data-volume

  restartExistWorkloads:
    args:
    - --restartExistWorkloads

  bpfExclusiveMode:
    args:
    - --bpfExclusiveMode

  metrics:
    args:
    - --enableMetrics

  resources:
    limits:
      cpu: 200m
      memory: 300Mi
    requests:
      cpu: 100m
      memory: 200Mi

  autoscaling:
    enabled: false
    minReplicas: 3
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  affinity: {}

  tolerations: []


agent:
  name: agent

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podSecurityContext: {}

  image:
    name: varmor
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""
  
  securityContext:
    capabilities:
      add:
      - SYS_ADMIN
      - BPF
      - SYS_RESOURCE
      - SYS_PTRACE
      - MAC_ADMIN
      - IPC_LOCK
    runAsUser: 0

  args: []

  network:
    hostNetwork: false
    readinessPort: 6080

  appArmorLsmEnforcer:
    volumeMounts:
    - mountPath: /sys/module/apparmor
      name: apparmor
    - mountPath: /etc/apparmor.d
      name: apparmor-dir
    volumes:
    - hostPath:
        path: /sys/module/apparmor
        type: Directory
      name: apparmor
    - hostPath:
        path: /var/run/varmor/apparmor.d
        type: DirectoryOrCreate
      name: apparmor-dir
    resources:
      limits:
        cpu: 200m
        memory: 100Mi
      requests:
        cpu: 100m
        memory: 40Mi

  bpfLsmEnforcer:
    args:
    - --enableBpfEnforcer
    resources:
      limits:
        cpu: 200m
        memory: 200Mi
      requests:
        cpu: 100m
        memory: 100Mi

  unloadAllAaProfiles:
    args:
    - --unloadAllAaProfiles

  removeAllSeccompProfiles:
    args:
    - --removeAllSeccompProfiles

  behaviorModeling:
    args:
    - --enableBehaviorModeling
    # The volume caches the audit data in the agent pod during modeling
    volumeMounts:
    - mountPath: /var/log/varmor/auditdata
      name: data-volume
    volumes:
    - emptyDir:
        sizeLimit: 500Mi
      name: data-volume
    resources:
      limits:
        cpu: 2
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 500Mi

  bpfRelated:
    volumeMounts:
    - mountPath: /sys/fs/bpf
      name: bpffs
    - mountPath: /sys/kernel/btf/vmlinux
      name: btf
    volumes:
    - hostPath:
        path: /sys/fs/bpf
        type: Directory
      name: bpffs
    - hostPath:
        path: /sys/kernel/btf/vmlinux
        type: File
      name: btf

  nodeSelector: {}

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/os
            operator: In
            values:
            - linux
          - key: node.kubernetes.io/instance-type
            operator: NotIn
            values:
            - virtual-node

  tolerations:
    - effect: NoSchedule
      operator: Exists


classifier:
  name: classifier

  replicaCount: 1

  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  image:
    name: classifier
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  podAnnotations: {}

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - MKNOD
      - NET_RAW

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 3
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  affinity: {}

  tolerations: []
